{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "918525d9",
   "metadata": {},
   "source": [
    "# Multi-Factor Alpha Engine - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides an end-to-end demonstration of the Alpha Engine pipeline with exploratory data analysis.\n",
    "\n",
    "## Sections:\n",
    "1. Data Loading and Processing\n",
    "2. Feature Engineering Analysis\n",
    "3. Factor Performance Analysis\n",
    "4. Model Training and Evaluation\n",
    "5. Portfolio Construction Demo\n",
    "6. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import alpha engine modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from alpha_engine.data import load_and_process_data\n",
    "from alpha_engine.features import FeatureEngine\n",
    "from alpha_engine.models import ModelEnsemble\n",
    "from alpha_engine.portfolio import PortfolioOptimizer\n",
    "from alpha_engine.backtest import Backtester, PerformanceAnalyzer\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb3e2e",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e57481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "print(\"Loading and processing equity data...\")\n",
    "data = load_and_process_data(config_path=\"../config.yaml\", force_refresh=False)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Date range: {data['Date'].min()} to {data['Date'].max()}\")\n",
    "print(f\"Number of tickers: {data['ticker'].nunique()}\")\n",
    "print(f\"Columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e92ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Number of tickers over time\n",
    "ticker_counts = data.groupby('Date')['ticker'].nunique()\n",
    "axes[0, 0].plot(ticker_counts.index, ticker_counts.values)\n",
    "axes[0, 0].set_title('Number of Tickers Over Time')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Daily return distribution\n",
    "axes[0, 1].hist(data['return_1d'].dropna(), bins=100, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Daily Return Distribution')\n",
    "axes[0, 1].set_xlabel('Daily Return')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Volume distribution (log scale)\n",
    "axes[1, 0].hist(np.log(data['Volume'] + 1), bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Log Volume Distribution')\n",
    "axes[1, 0].set_xlabel('Log(Volume)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Price distribution (log scale)\n",
    "axes[1, 1].hist(np.log(data['Close']), bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('Log Price Distribution')\n",
    "axes[1, 1].set_xlabel('Log(Price)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a70ee0",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer features\n",
    "print(\"Engineering features...\")\n",
    "engine = FeatureEngine(config_path=\"../config.yaml\")\n",
    "featured_data = engine.engineer_features(data)\n",
    "\n",
    "# Get feature columns\n",
    "feature_cols = [col for col in featured_data.columns if col.endswith('_zscore')]\n",
    "print(f\"\\nTotal features engineered: {len(feature_cols)}\")\n",
    "print(f\"Feature categories:\")\n",
    "\n",
    "# Categorize features\n",
    "categories = {\n",
    "    'Value': ['book_to_market', 'earnings_yield', 'sales_to_price', 'dividend_yield'],\n",
    "    'Momentum': ['momentum_12_1', 'momentum_6_1', 'short_term_reversal', 'price_trend'],\n",
    "    'Quality': ['roe_proxy', 'profit_margin_proxy', 'accruals_proxy', 'earnings_quality'],\n",
    "    'Size': ['market_cap_proxy', 'log_market_cap', 'relative_size'],\n",
    "    'Liquidity': ['turnover', 'amihud_illiquidity', 'bid_ask_spread', 'volume_trend'],\n",
    "    'Volatility': ['realized_vol_21d', 'realized_vol_63d', 'vol_of_vol', 'ewma_vol'],\n",
    "    'Technical': ['rsi_14', 'macd_signal', 'bollinger_position', 'williams_r'],\n",
    "    'Risk': ['beta', 'idiosyncratic_vol', 'return_skewness', 'return_kurtosis']\n",
    "}\n",
    "\n",
    "for category, features in categories.items():\n",
    "    available_features = [f for f in features if f in featured_data.columns]\n",
    "    print(f\"  {category}: {len(available_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis\n",
    "sample_features = [f for f in feature_cols[:20]]  # Sample of features for visualization\n",
    "recent_data = featured_data[featured_data['Date'] >= '2020-01-01']\n",
    "correlation_matrix = recent_data[sample_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix (Sample)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c412e",
   "metadata": {},
   "source": [
    "## 3. Factor Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze factor performance over time\n",
    "def calculate_factor_ic(data, factor_col, return_col='return_21d', periods=21):\n",
    "    \"\"\"Calculate Information Coefficient for a factor.\"\"\"\n",
    "    # Forward returns\n",
    "    data = data.sort_values(['ticker', 'Date'])\n",
    "    data['forward_return'] = data.groupby('ticker')[return_col].shift(-periods)\n",
    "    \n",
    "    # Calculate IC by date\n",
    "    ic_by_date = data.groupby('Date').apply(\n",
    "        lambda x: x[factor_col].corr(x['forward_return'])\n",
    "    ).dropna()\n",
    "    \n",
    "    return ic_by_date\n",
    "\n",
    "# Calculate IC for sample factors\n",
    "sample_factors = ['momentum_12_1_zscore', 'book_to_market_zscore', \n",
    "                 'realized_vol_21d_zscore', 'rsi_14_zscore']\n",
    "\n",
    "ic_results = {}\n",
    "for factor in sample_factors:\n",
    "    if factor in featured_data.columns:\n",
    "        ic_ts = calculate_factor_ic(featured_data, factor)\n",
    "        ic_results[factor.replace('_zscore', '')] = ic_ts\n",
    "\n",
    "# Plot IC time series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (factor_name, ic_ts) in enumerate(ic_results.items()):\n",
    "    if i < 4:\n",
    "        axes[i].plot(ic_ts.index, ic_ts.values, alpha=0.7)\n",
    "        axes[i].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        axes[i].set_title(f'{factor_name} - Information Coefficient')\n",
    "        axes[i].set_ylabel('IC')\n",
    "        \n",
    "        # Add rolling mean\n",
    "        rolling_ic = ic_ts.rolling(252).mean()\n",
    "        axes[i].plot(rolling_ic.index, rolling_ic.values, \n",
    "                    color='red', linewidth=2, label='1Y Rolling Mean')\n",
    "        axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# IC statistics\n",
    "print(\"\\nInformation Coefficient Statistics:\")\n",
    "for factor_name, ic_ts in ic_results.items():\n",
    "    mean_ic = ic_ts.mean()\n",
    "    std_ic = ic_ts.std()\n",
    "    ir = mean_ic / std_ic if std_ic > 0 else 0\n",
    "    print(f\"{factor_name:20} | Mean IC: {mean_ic:6.3f} | Std IC: {std_ic:6.3f} | IR: {ir:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11c53d",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ed22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "print(\"Preparing training data...\")\n",
    "X, y = engine.get_feature_matrix(\n",
    "    featured_data, \n",
    "    use_zscore=True,\n",
    "    start_date='2010-01-01',\n",
    "    end_date='2020-01-01'\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X.shape}\")\n",
    "print(f\"Target statistics: Mean={y.mean():.4f}, Std={y.std():.4f}\")\n",
    "\n",
    "# Train ensemble\n",
    "print(\"\\nTraining model ensemble...\")\n",
    "import yaml\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "ensemble = ModelEnsemble(config)\n",
    "ensemble.fit(X, y, blend_method='equal')\n",
    "\n",
    "print(f\"Ensemble weights: {ensemble.weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance comparison\n",
    "models_performance = {}\n",
    "\n",
    "for model_name, model in ensemble.models.items():\n",
    "    if model.is_fitted:\n",
    "        predictions = model.predict(X)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        correlation = np.corrcoef(y, predictions)[0, 1]\n",
    "        hit_rate = (np.sign(y) == np.sign(predictions)).mean()\n",
    "        \n",
    "        models_performance[model_name] = {\n",
    "            'correlation': correlation,\n",
    "            'hit_rate': hit_rate\n",
    "        }\n",
    "\n",
    "# Ensemble predictions\n",
    "ensemble_pred = ensemble.predict(X)\n",
    "ensemble_corr = np.corrcoef(y, ensemble_pred)[0, 1]\n",
    "ensemble_hit_rate = (np.sign(y) == np.sign(ensemble_pred)).mean()\n",
    "models_performance['ensemble'] = {\n",
    "    'correlation': ensemble_corr,\n",
    "    'hit_rate': ensemble_hit_rate\n",
    "}\n",
    "\n",
    "# Plot performance comparison\n",
    "performance_df = pd.DataFrame(models_performance).T\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "performance_df['correlation'].plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Model Correlation with Future Returns')\n",
    "axes[0].set_ylabel('Correlation')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "performance_df['hit_rate'].plot(kind='bar', ax=axes[1], color='lightgreen')\n",
    "axes[1].set_title('Model Hit Rate (Directional Accuracy)')\n",
    "axes[1].set_ylabel('Hit Rate')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Random')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(performance_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0573464",
   "metadata": {},
   "source": [
    "## 5. Portfolio Construction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio construction example\n",
    "print(\"Demonstrating portfolio construction...\")\n",
    "\n",
    "# Generate sample signals\n",
    "recent_data = featured_data[featured_data['Date'] >= '2023-01-01'].groupby('ticker').last()\n",
    "sample_X = recent_data[feature_cols].fillna(0)\n",
    "signals = pd.Series(ensemble.predict(sample_X), index=sample_X.index)\n",
    "\n",
    "print(f\"Generated signals for {len(signals)} stocks\")\n",
    "print(f\"Signal statistics: Mean={signals.mean():.4f}, Std={signals.std():.4f}\")\n",
    "\n",
    "# Create return history for risk estimation\n",
    "return_history = featured_data[featured_data['Date'] >= '2022-01-01'].pivot(\n",
    "    index='Date', columns='ticker', values='return_1d'\n",
    ").dropna(axis=1, thresh=200)  # Require at least 200 observations\n",
    "\n",
    "# Portfolio optimization\n",
    "optimizer = PortfolioOptimizer('../config.yaml')\n",
    "positions, metrics = optimizer.create_dollar_neutral_portfolio(\n",
    "    signals, return_history, capital=1000000\n",
    ")\n",
    "\n",
    "print(f\"\\nPortfolio Construction Results:\")\n",
    "print(f\"Number of positions: {len(positions)}\")\n",
    "print(f\"Long positions: {(positions > 0).sum()}\")\n",
    "print(f\"Short positions: {(positions < 0).sum()}\")\n",
    "print(f\"\\nPortfolio Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio composition analysis\n",
    "if len(positions) > 0:\n",
    "    # Top long and short positions\n",
    "    long_positions = positions[positions > 0].sort_values(ascending=False)\n",
    "    short_positions = positions[positions < 0].sort_values()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Top 10 long positions\n",
    "    if len(long_positions) > 0:\n",
    "        top_long = long_positions.head(10)\n",
    "        axes[0].barh(range(len(top_long)), top_long.values, color='green', alpha=0.7)\n",
    "        axes[0].set_yticks(range(len(top_long)))\n",
    "        axes[0].set_yticklabels(top_long.index)\n",
    "        axes[0].set_title('Top 10 Long Positions')\n",
    "        axes[0].set_xlabel('Position Size ($)')\n",
    "    \n",
    "    # Top 10 short positions\n",
    "    if len(short_positions) > 0:\n",
    "        top_short = short_positions.head(10)\n",
    "        axes[1].barh(range(len(top_short)), top_short.values, color='red', alpha=0.7)\n",
    "        axes[1].set_yticks(range(len(top_short)))\n",
    "        axes[1].set_yticklabels(top_short.index)\n",
    "        axes[1].set_title('Top 10 Short Positions')\n",
    "        axes[1].set_xlabel('Position Size ($)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Position size distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(positions.values, bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.title('Portfolio Position Size Distribution')\n",
    "    plt.xlabel('Position Size ($)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4596b",
   "metadata": {},
   "source": [
    "## 6. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample backtest results for visualization\n",
    "# This is a simplified example - full backtest would be run via run_pipeline.py\n",
    "\n",
    "# Generate synthetic performance data for demonstration\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2020-01-01', '2023-12-31', freq='M')\n",
    "n_periods = len(dates)\n",
    "\n",
    "# Simulate monthly returns\n",
    "alpha_returns = np.random.normal(0.01, 0.04, n_periods)  # 1% monthly mean, 4% vol\n",
    "benchmark_returns = np.random.normal(0.007, 0.035, n_periods)  # 0.7% monthly mean, 3.5% vol\n",
    "\n",
    "# Create performance DataFrame\n",
    "performance_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'alpha_return': alpha_returns,\n",
    "    'benchmark_return': benchmark_returns\n",
    "})\n",
    "performance_data['alpha_cumulative'] = (1 + performance_data['alpha_return']).cumprod()\n",
    "performance_data['benchmark_cumulative'] = (1 + performance_data['benchmark_return']).cumprod()\n",
    "performance_data['alpha_value'] = 1000000 * performance_data['alpha_cumulative']\n",
    "performance_data['benchmark_value'] = 1000000 * performance_data['benchmark_cumulative']\n",
    "\n",
    "# Plot equity curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Equity curve comparison\n",
    "axes[0, 0].plot(performance_data['date'], performance_data['alpha_value'], \n",
    "               label='Alpha Strategy', linewidth=2, color='blue')\n",
    "axes[0, 0].plot(performance_data['date'], performance_data['benchmark_value'], \n",
    "               label='Benchmark', linewidth=2, color='orange')\n",
    "axes[0, 0].set_title('Portfolio Value Comparison')\n",
    "axes[0, 0].set_ylabel('Portfolio Value ($)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling Sharpe ratio\n",
    "rolling_window = 12\n",
    "alpha_rolling_sharpe = performance_data['alpha_return'].rolling(rolling_window).mean() / \\\n",
    "                      performance_data['alpha_return'].rolling(rolling_window).std() * np.sqrt(12)\n",
    "benchmark_rolling_sharpe = performance_data['benchmark_return'].rolling(rolling_window).mean() / \\\n",
    "                          performance_data['benchmark_return'].rolling(rolling_window).std() * np.sqrt(12)\n",
    "\n",
    "axes[0, 1].plot(performance_data['date'], alpha_rolling_sharpe, \n",
    "               label='Alpha Strategy', linewidth=2, color='blue')\n",
    "axes[0, 1].plot(performance_data['date'], benchmark_rolling_sharpe, \n",
    "               label='Benchmark', linewidth=2, color='orange')\n",
    "axes[0, 1].set_title('Rolling 12-Month Sharpe Ratio')\n",
    "axes[0, 1].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly returns distribution\n",
    "axes[1, 0].hist(performance_data['alpha_return'], bins=20, alpha=0.7, \n",
    "               label='Alpha Strategy', color='blue', edgecolor='black')\n",
    "axes[1, 0].hist(performance_data['benchmark_return'], bins=20, alpha=0.7, \n",
    "               label='Benchmark', color='orange', edgecolor='black')\n",
    "axes[1, 0].set_title('Monthly Returns Distribution')\n",
    "axes[1, 0].set_xlabel('Monthly Return')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Excess returns\n",
    "excess_returns = performance_data['alpha_return'] - performance_data['benchmark_return']\n",
    "axes[1, 1].plot(performance_data['date'], excess_returns, \n",
    "               linewidth=1, alpha=0.7, color='green')\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_title('Monthly Excess Returns')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Excess Return')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance summary\n",
    "final_alpha_value = performance_data['alpha_value'].iloc[-1]\n",
    "final_benchmark_value = performance_data['benchmark_value'].iloc[-1]\n",
    "alpha_total_return = (final_alpha_value / 1000000) - 1\n",
    "benchmark_total_return = (final_benchmark_value / 1000000) - 1\n",
    "alpha_sharpe = performance_data['alpha_return'].mean() / performance_data['alpha_return'].std() * np.sqrt(12)\n",
    "benchmark_sharpe = performance_data['benchmark_return'].mean() / performance_data['benchmark_return'].std() * np.sqrt(12)\n",
    "\n",
    "print(\"\\nðŸ“Š PERFORMANCE SUMMARY (Sample Data)\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Alpha Strategy:\")\n",
    "print(f\"  Total Return: {alpha_total_return:.1%}\")\n",
    "print(f\"  Annualized Sharpe: {alpha_sharpe:.2f}\")\n",
    "print(f\"  Final Value: ${final_alpha_value:,.0f}\")\n",
    "print(f\"\\nBenchmark:\")\n",
    "print(f\"  Total Return: {benchmark_total_return:.1%}\")\n",
    "print(f\"  Annualized Sharpe: {benchmark_sharpe:.2f}\")\n",
    "print(f\"  Final Value: ${final_benchmark_value:,.0f}\")\n",
    "print(f\"\\nExcess Performance:\")\n",
    "print(f\"  Excess Return: {alpha_total_return - benchmark_total_return:.1%}\")\n",
    "print(f\"  Information Ratio: {excess_returns.mean() / excess_returns.std() * np.sqrt(12):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9942a13",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the key components of the Multi-Factor Equity Alpha Engine:\n",
    "\n",
    "1. **Data Processing**: Successfully loaded and cleaned equity data\n",
    "2. **Feature Engineering**: Generated 35+ factors across multiple categories\n",
    "3. **Model Training**: Trained ensemble of Ridge, XGBoost, and Neural Network models\n",
    "4. **Portfolio Construction**: Applied Kelly optimization with risk constraints\n",
    "5. **Performance Analysis**: Visualized returns, risk metrics, and benchmark comparison\n",
    "\n",
    "### Next Steps:\n",
    "- Run the full pipeline: `python run_pipeline.py --start 2005-01-01 --end 2024-06-30`\n",
    "- Explore factor performance in different market regimes\n",
    "- Analyze sector and style exposures\n",
    "- Implement additional risk management techniques\n",
    "\n",
    "### Key Metrics Target:\n",
    "- **Target**: 13% CAGR, 1.3 Sharpe ratio\n",
    "- **Benchmark**: S&P 1500 with ~7% CAGR, 0.6 Sharpe ratio\n",
    "\n",
    "The engine is designed to be production-ready with modular components, comprehensive testing, and professional reporting capabilities."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
